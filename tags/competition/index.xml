<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Competition | ゲッタ〜のHP</title>
    <link>https://kokuyokugetter.github.io/tags/competition/</link>
      <atom:link href="https://kokuyokugetter.github.io/tags/competition/index.xml" rel="self" type="application/rss+xml" />
    <description>Competition</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Sun, 17 Sep 2023 22:48:26 +0900</lastBuildDate>
    <image>
      <url>img/map[gravatar:%!s(bool=false) shape:circle]</url>
      <title>Competition</title>
      <link>https://kokuyokugetter.github.io/tags/competition/</link>
    </image>
    
    <item>
      <title>Nishika 金融時系列分析18位解法</title>
      <link>https://kokuyokugetter.github.io/post/nishika_finance-ts/</link>
      <pubDate>Sun, 17 Sep 2023 22:48:26 +0900</pubDate>
      <guid>https://kokuyokugetter.github.io/post/nishika_finance-ts/</guid>
      <description>&lt;br&gt;
&lt;p&gt;
&lt;a href=&#34;https://competition.nishika.com/competitions/finance_ts/ranking&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;実際の順位表&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;ranking.png&#34; alt=&#34;myRank.png&#34;&gt;&lt;/p&gt;
&lt;br&gt;
&lt;h2 id=&#34;tldr&#34;&gt;TLDR&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;基本的には
&lt;a href=&#34;https://competition.nishika.com/competitions/finance_ts/topics/630&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;このトピック&lt;/a&gt;をそのまま丸パクリ。&lt;/li&gt;
&lt;li&gt;加えて、説明変数のクラスタリングにより説明変数の総合得点化を行った。&lt;/li&gt;
&lt;li&gt;クラスタ数・アンサンブルするモデル数・エポック数についてハイパーパラメータ探索を行った。その際の評価を慎重に行った。&lt;/li&gt;
&lt;li&gt;Notebookは
&lt;a href=&#34;https://competition.nishika.com/competitions/finance_ts/topics/640&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;こちら&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;h2 id=&#34;コンペ概要&#34;&gt;コンペ概要&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;本コンペでは、金融関連企業様のデータを用いて、数百の匿名特徴量を用い、金融に関する或るターゲット値を予測することをテーマとします。
予測精度の評価はcosine similarityにて行います。
このコンペティションでは、テストデータの約29%により暫定スコアが計算され、残りの約71%により最終スコアが計算されます。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;
&lt;a href=&#34;https://competition.nishika.com/competitions/finance_ts/summary&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://competition.nishika.com/competitions/finance_ts/summary&lt;/a&gt; より引用&lt;/p&gt;
&lt;p&gt;特徴量が匿名であり、この項目はどういう意味があるのか、などの推測が難しくなっている。&lt;/p&gt;
&lt;p&gt;また、評価指標がコサイン類似度であることもなかなか癖があり、難しい点と個人的には思う。&lt;/p&gt;
&lt;br&gt;
&lt;h2 id=&#34;eda&#34;&gt;EDA&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;各説明変数は5段階になっている。アンケート的なものを想像し、似たような項目はまとめて総合得点化することが効果的かもしれないと考えた。&lt;/li&gt;
&lt;li&gt;targetの値が10段階しかないことがわかる。
&lt;ul&gt;
&lt;li&gt;最終的には連続値として回帰を行ったが、multiclassで10クラスの確率を予測し、10クラスの値を予測確率で重みつき平均をとったものも効果的だったように思う。&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://competition.nishika.com/competitions/finance_ts/topics/629&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;こちらのトピック&lt;/a&gt;より、スコアのばらつきが大きそうであることを確認。&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;h2 id=&#34;前加工モデル作成&#34;&gt;前加工＋モデル作成&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;説明変数の類似項目がどれかは匿名化によって一見では分からないため、
&lt;a href=&#34;https://datadriven-rnd.com/hierarchical-clustering/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;こちらのブログ&lt;/a&gt;を参考に、相関係数（絶対値はかけなかった）で説明変数のクラスタリングを行った。
&lt;ul&gt;
&lt;li&gt;クラスタ数を後述のハイパーパラメータとして探索し、220を採用した。このクラスタ内の説明変数の和を新たな説明変数として用い、変数を220まで減らすことができた。
&lt;ul&gt;
&lt;li&gt;もちろん、説明変数を減らすことで情報が減っているので、やるべきかという問題はある。&lt;/li&gt;
&lt;li&gt;絶対値をかけてクラスタリングを行い、その正負を考慮して和を取る方が良さそうだが、すぐには実装が思いつかなかったため断念。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://competition.nishika.com/competitions/finance_ts/topics/630&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;こちらのトピック&lt;/a&gt;より、以下の2点を丸パクリ。
&lt;ul&gt;
&lt;li&gt;グループ (id // 10,000) の追加。テストデータのグループは66に設定。&lt;/li&gt;
&lt;li&gt;LightGBMでの回帰モデルを作成とバギングとアンサンブル&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;h2 id=&#34;ハイパーパラメータの調整&#34;&gt;ハイパーパラメータの調整&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;クラスタ数・アンサンブルするモデル数・エポック数についてハイパーパラメータ探索を行った。
&lt;ul&gt;
&lt;li&gt;trainデータを40万件と26万件に分けてコサイン類似度のスコアを見て最も良さそうなパラメータを採用する。&lt;/li&gt;
&lt;li&gt;その際に、±0.01程度スコアが前後することが分かっていたので、26万件からランダムに29%と71%に分けて1000回スコアを出してその分布（平均値）を見ることにより決定した。&lt;/li&gt;
&lt;li&gt;また、publicスコアが低い（分布の下側にいる）場合にprivateスコアが高くなる（分布の上側にいる）傾向にあるような気がしたが、提出したpublicスコアが高いか低いかわからないしあまり意味はない？&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;h2 id=&#34;結果&#34;&gt;結果&lt;/h2&gt;
&lt;p&gt;以上の方法により、Publicスコア0.049781、Privateスコア0.033341で18位となった。&lt;/p&gt;
&lt;p&gt;（Publicスコアは黒魔術&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;入りのものが0.0565と自己ベストだったが、そちらのPrivateスコアは0.014404。）&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;https://competition.nishika.com/competitions/finance_ts/topics/640&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Nishika内のトピックにnotebookアリ&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;宝くじ・運ゲーコンペと噂されているように、偶然で上位に行く可能性が十分にあるコンペだと思われるので、今回の解法が良いものかは分からないが、実際大きなshakeが起きなかったので、ハイパーパラメータ探索などにおいて堅いものを選べたのではないかと思っている。&lt;/p&gt;
&lt;br&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;単純に前処理も何もせず、shuffleありの5-foldで10クラスの分類をLightGBMで行い、重みつき平均を行ったものが、privateスコアは0.037098と2位相当のスコアになっていた。しかしpublicスコアが0.031396と少々低く、最終提出の中に含めることはできなかった。
&lt;a href=&#34;https://competition.nishika.com/competitions/finance_ts/topics/651&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;実際のnotebook&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34;&gt;
&lt;p&gt;丸パクリしたトピックに記載のある後処理。&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Nishikaの生鮮野菜のコンペで16位取るためにやったこと</title>
      <link>https://kokuyokugetter.github.io/post/nishika_yasai/</link>
      <pubDate>Mon, 22 Aug 2022 22:48:26 +0900</pubDate>
      <guid>https://kokuyokugetter.github.io/post/nishika_yasai/</guid>
      <description>&lt;br&gt;
&lt;p&gt;
&lt;a href=&#34;https://www.nishika.com/competitions/32/ranking&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;実際の順位表&lt;/a&gt;&lt;/p&gt;
 &lt;img src=&#34;myRank.png&#34; width=&#34;&#34; alt=&#34;fig1&#34;&gt; 
&lt;br&gt;
&lt;p&gt;MLエンジニアに転職したのもあって勉強がてらいろんな方法を試していたらそこそこの順位になったので、&lt;/p&gt;
&lt;p&gt;どんなことをやっていたか書き残していこうと思います。&lt;/p&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#データについて&#34;&gt;データについて&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#eda探索的データ分析ベースラインモデルの構築&#34;&gt;EDA（探索的データ分析）＋ベースラインモデルの構築&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#前加工&#34;&gt;前加工&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#作成したモデル&#34;&gt;作成したモデル&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#モデルの評価等&#34;&gt;モデルの評価等&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#提出前加工と提出しながら調整&#34;&gt;提出前加工と提出しながら調整&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#結果考察その他&#34;&gt;結果＋考察その他&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#やりたかったができなかったメモ&#34;&gt;やりたかったができなかったメモ&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;br&gt;
&lt;h2 id=&#34;データについて&#34;&gt;データについて&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;本コンペでは、生鮮野菜の価格予測をテーマにします。
目的変数は、大田市場にて相対取引されている各野菜の日次の卸売価格とし、予測期間は最も多くの種類の野菜が市場に出ている2022年5月とします。
予測対象の野菜は、以下16品目です。
きゅうり,こまつな,じゃがいも,そらまめ,だいこん,なましいたけ,にんじん,ねぎ,はくさい,ほうれんそう,キャベツ,セルリー,トマト,ピーマン,ミニトマト,レタス&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;
&lt;a href=&#34;https://www.nishika.com/competitions/32/summary#description&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.nishika.com/competitions/32/summary#description&lt;/a&gt; より引用&lt;/p&gt;
&lt;p&gt;今回のデータはテーブルデータなのですが&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;、titanic等とは違って時系列データになっているので、今までのtitanicなどの練習コンペとは一味違うデータとなっていました。&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;br&gt;
&lt;h2 id=&#34;eda探索的データ分析ベースラインモデルの構築&#34;&gt;EDA（探索的データ分析）＋ベースラインモデルの構築&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;時系列データといえば、ARモデルやARIMAモデル、prophetなどを聞いたことがあったので、その辺を軽く試しつつ、EDAを手探りで行っていきました。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;とはいえ、時系列データのEDAって何をすればいいんだ？と思いながらデータを眺めたりしていました。グラフを書くにも時系列でプロットする方法に手こずったりしていました。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;それぞれtestデータに含まれる野菜の種類を抜き出して、価格の移動平均線をいろんな日数でプロットしたり、コレログラムを描いたりしました。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;また、statsmodels.tsa.seasonal.seasonal_decompose.plot()という時系列データを眺めるのに？便利な関数があることも分かったのは良かったと思います。
&lt;img src=&#34;seasonal_decompose.png&#34; width=&#34;&#34; alt=&#34;fig2&#34;&gt; &lt;em&gt;こんな感じでトレンドとか季節成分とかをいい感じに分解してくれる&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ARモデル等それぞれのモデルでパラメータとか気にせずに適当にやった結果は以下の通り
&lt;img src=&#34;AR.png&#34; width=&#34;&#34; alt=&#34;fig3&#34;&gt; &lt;em&gt;良さそう&lt;/em&gt;
&lt;img src=&#34;ARIMA.png&#34; width=&#34;&#34; alt=&#34;fig4&#34;&gt; &lt;em&gt;う〜ん。。。&lt;/em&gt;
&lt;img src=&#34;prophet.png&#34; width=&#34;&#34; alt=&#34;fig5&#34;&gt; &lt;em&gt;まあまあ&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;あとは生産地を考慮するかどうかでこういうプロットも描いたりした。
&lt;img src=&#34;regional_difference.png&#34; width=&#34;&#34; alt=&#34;fig6&#34;&gt; &lt;em&gt;生産地の変化する点においても、ある程度連続的に見えたので地域差は気にしなくていいことにした&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;h2 id=&#34;前加工&#34;&gt;前加工&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;前加工としては、公式のチュートリアルコードを参考に進めていきました。&lt;/li&gt;
&lt;li&gt;まず、市場が開いてない日があるとprophet等の予測をどう解釈していいのか分かりにくかったのもあり&lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;、（やっていいのかわからないですが）開いてない日の価格も線形補間したデータを作成しました。&lt;/li&gt;
&lt;li&gt;データを見て、あまりに予測不可能そうな山／谷を過学習するのを緩和するために、移動平均をとったデータなども作成しました。&lt;/li&gt;
&lt;li&gt;また、チュートリアルのデータは月平均（だったかな？）なので、そこは日次データに直して天気データとマージしたデータなどを作成しました。&lt;/li&gt;
&lt;li&gt;予測するにあたって、ちょうどその時間の説明変数をそのまま使うことはできないので、価格データや天候のデータそれぞれについてラグ特徴量をとったものを作成しました。&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;h2 id=&#34;作成したモデル&#34;&gt;作成したモデル&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;prophetモデル&lt;/li&gt;
&lt;li&gt;ARモデル
上のベースラインモデル作成時において割と良さそうだったARとprophetは採用。&lt;/li&gt;
&lt;li&gt;RandomForestモデル
よく使われがちなRF。&lt;/li&gt;
&lt;li&gt;SGDregressiorモデル&lt;/li&gt;
&lt;li&gt;ElasticNetモデル
ラグ特徴量を多くとっているので、変に過学習しないようにという意図で採用&lt;/li&gt;
&lt;li&gt;lightGBMモデル
よく使われがちなlightGBM。
これらのモデルを最後にアンサンブルして提出しました。&lt;/li&gt;
&lt;/ol&gt;
&lt;br&gt;
&lt;h2 id=&#34;モデルの評価等&#34;&gt;モデルの評価等&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;評価用に202204のデータをsplitしました&lt;/li&gt;
&lt;li&gt;全訓練データを使うと評価のスコアがイマイチになることがあり、スコアベースで適切な年から最新のデータまでを入れるようにしました。&lt;/li&gt;
&lt;li&gt;テストデータを予測するときに時系列の一番近いはずのデータ（202204データ）を含めて再学習して予測しました。&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;h2 id=&#34;提出前加工と提出しながら調整&#34;&gt;提出前加工と提出しながら調整&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;色々アンサンブルとかブレンディング
&lt;ul&gt;
&lt;li&gt;それぞれのモデルが予測した結果の単純平均をとったもの -&amp;gt; 微妙&lt;/li&gt;
&lt;li&gt;ノリで重みをつけて平均 -&amp;gt; 有効だが、低いモデルの予測がいらなくなって消えていく。それがいいのかわからない。&lt;/li&gt;
&lt;li&gt;202204のデータを評価用にして、線形回帰で重みを計算 -&amp;gt; 負の係数が出てしまい、それぞれのモデルはピッタリ合うようにしていることを鑑みるとやっちゃダメな気がした。&lt;/li&gt;
&lt;li&gt;scipy.optimize.nnlsで非負最小二乗法で重みを計算 -&amp;gt; 微妙だった&lt;/li&gt;
&lt;li&gt;野菜の種別ごとに非負最小二乗法で重みを計算 -&amp;gt; 評価データに対してはメチャクチャ良かったが、testはだめだった&lt;/li&gt;
&lt;li&gt;Public scoreベースで重みをつけたアンサンブル -&amp;gt; 結構有効だった。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;実は途中までチュートリアルのPublic Scoreに全く勝てなかったのが辛かった。途中でラグ特徴量を大量採用しようやくチュートリアルのスコアを超えたので、チュートリアルの結果は最終的には採用しなかった。&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;h2 id=&#34;結果考察その他&#34;&gt;結果＋考察その他&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;最終的にPublic Scoreベースのアンサンブルと、ノリで重みつけした2モデルを提出し、天候と価格のラグ特徴量を全て使ったscoreベースのアンサンブルが13.903593のFinal Scoreで16位になりました。初銀メダル！&lt;/li&gt;
&lt;li&gt;過去に出した全ての最終スコアの一覧を見ていると、ランダムフォレスト単体のモデルが12.98でこれを提出していれば5位になっていたようです。単体スコアも低くないので、やはりランダムフォレストは未だ現役だなと思いました。&lt;/li&gt;
&lt;li&gt;最後の1ヶ月は他の勉強をしていたこともあり、なかなかコンペをやっていませんでしたが、4位解法(
&lt;a href=&#34;https://www.nishika.com/competitions/32/topics/353&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.nishika.com/competitions/32/topics/353&lt;/a&gt;)を見ると、メチャクチャ単純なこともあり、自分が本気でラスト1ヶ月取り組んでも逆に複雑化して泥沼だっただろうなと思います。&lt;/li&gt;
&lt;li&gt;まああとは時系列でデータもそんなに多くないのもあって、ある程度のScoreのブレはありそうなので、そこまで細かいことは言うまいかなとは思います。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;やりたかったができなかったメモ&#34;&gt;やりたかったができなかったメモ&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;天気のみデータで学習するとスコアは微妙そうだが、多様性は得られるのではないか。&lt;/li&gt;
&lt;li&gt;RNNなどのディープラーニング手法も可能なら試したい&lt;/li&gt;
&lt;li&gt;prophetに説明変数追加できるの知らなかったので追加してもいい -&amp;gt; 
&lt;a href=&#34;https://qiita.com/japanesebonobo/items/e674359618a879a49c05&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://qiita.com/japanesebonobo/items/e674359618a879a49c05&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;時系列要素を残すために説明変数に基準日から数えて何日目かを追加していたので、線形補間してないデータで予測しても良かったかも&lt;/li&gt;
&lt;li&gt;勾配降下法を用いる回帰で標準化するのを忘れていた。（elastic netやsgd）&lt;/li&gt;
&lt;li&gt;今の野菜に対して今の気温データ等で当てはめるのはワンチャンあるはず。そして気温データ等は季節変動があることを考えると時系列モデルでの予測が容易に思われる。→気候データをARとかARIMA等でフィッティングしてからその気候データを使ってmode_priceを予測する。&lt;/li&gt;
&lt;li&gt;市場が休みの前日は叩き売りするのではないか検証&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;画像処理等はマシンスペック的にもやりづらいということでテーブルデータかつactiveなコンペをいろんなサイト(kaggle, signate, nishika, probspace)で探しました。&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34;&gt;
&lt;p&gt;この前に
&lt;a href=&#34;https://signate.jp/competitions/737&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;【第23回_Tier限定コンペ】採血データを使った心不全予測&lt;/a&gt; もactiveなテーブルデータコンペでしたが、こちらは初心者用なのでtitanic的な立ち位置として消費しました。&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34;&gt;
&lt;p&gt;データ点が等間隔であることが仮定されているような予測結果になった気がしますが、ちゃんと調べていないので嘘かもしれません。&amp;#160;&lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
